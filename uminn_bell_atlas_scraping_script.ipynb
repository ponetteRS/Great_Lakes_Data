{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''These are import statements that are used to make the code work from Python Libraries of code that provide python tools utilized below. \n",
    "DO NOT EDIT UNLESS AUTHORIZED.\n",
    "There are a couple more than necessary, but are included still incase any edits are needed in the future that might need these libraries.'''\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ssl\n",
    "import urllib.request, urllib.parse, urllib.error\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import glob\n",
    "import os.path\n",
    "import re\n",
    "from pandas.errors import EmptyDataError\n",
    "from datetime import date\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''EDIT WITH THE PATH OF THE TRACKING DOCUMENT ON THE COMPUTER WHERE THIS SCRIPT IS RAN.. It is essential that it is formated the same as the \n",
    "one Rochelle previously provided with the name of the species to be used as search queries on the Atlas Collection in the first line and \n",
    "that this information is present on the sheet titled \"Listed\".\n",
    "\n",
    "When editing, insert only the path of the file where this information can be found in between the quotation marks inside the parentheses.\n",
    "Similarly, if the species name exists on a sheet with a different name than \"LISTED\" in the first line then please insert that sheet name\n",
    "also in between the quotation marks after it says sheet_name = '''\n",
    "sourcesheet = pd.read_excel(r\"C:\\Users\\justi\\Downloads\\GLANSIS Spp. Tracking.xlsx\", sheet_name = \"Listed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''This segment of code will simply generate a list of names that will be searched. DO NOT EDIT.'''\n",
    "namelist= []\n",
    "for name in sourcesheet['Scientific Name']:\n",
    "    namelist.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "During the search, there were 1 searches with no results.\n"
     ]
    }
   ],
   "source": [
    "'''This is the key part of the script. This is where the web scraping happens. It should run automatically. DO NOT EDIT.'''\n",
    "\n",
    "atlas_url = \"https://bellatlas.umn.edu/collections/harvestparams.php\"\n",
    "#setting up driver for Selenium\n",
    "driver = webdriver.Firefox() #???Should I write a script for multiple Browsers?\n",
    "\n",
    "emptyresults = 0\n",
    "masterdataframe = pd.DataFrame()\n",
    "driver.maximize_window()\n",
    "scraped_dataframe = pd.DataFrame()\n",
    "scraped_dataframe.reset_index(drop=True)\n",
    "for speciesname in namelist[:]:\n",
    "    driver.get(atlas_url) # Goes to atlas\n",
    "    namebox = driver.find_element(by = By.XPATH, value = '//*[@id=\"taxa\"]')\n",
    "    searchbutton = driver.find_element(by = By.XPATH, value='/html/body/table/tbody/tr/td/div[4]/form/div[2]/div[1]/button') #selects the advanced search button based off the pulled tag from right clicking the inspected element\n",
    "    time.sleep(.5)\n",
    "    namebox.clear()\n",
    "    namebox.send_keys(speciesname)\n",
    "    searchbutton.click()\n",
    "\n",
    "    resultcount = driver.find_element(by=By.XPATH, value='/html/body/table/tbody/tr/td/div[4]/div/div[2]/div/div[4]/div[3]').text\n",
    "    resultcountnumberlist= list(map(int, list(filter(lambda x: x!= '', re.findall(r'\\d*', re.search(r'\\d* of \\d*', resultcount).group()))))) #first number in list is the total results displayed on the page, the second number is the total results\n",
    "\n",
    "#if there are not results\n",
    "    if resultcountnumberlist[1] == 0:\n",
    "        emptyresults+=1\n",
    "        continue\n",
    "#continue to next search\n",
    "    \n",
    "#if there are results\n",
    "    windowbefore = driver.window_handles[0]\n",
    "    downloadbutton = driver.find_element(by=By.XPATH, value='/html/body/table/tbody/tr/td/div[4]/div/div[2]/div/div[1]/form/button')\n",
    "    downloadbutton.click()\n",
    "    windowafter = driver.window_handles[1]\n",
    "    driver.switch_to.window(windowafter)\n",
    "    time.sleep(2)\n",
    "    driver.find_element(by=By.XPATH, value='/html/body/div[1]/div[2]/form/fieldset/table/tbody/tr[4]/td[2]/div/input[2]').click() #utf8 encoding\n",
    "    driver.find_element(by=By.XPATH, value='/html/body/div[1]/div[2]/form/fieldset/table/tbody/tr[5]/td[2]/div/input').click() #uncompresses download\n",
    "\n",
    "    downloadbutton=driver.find_element(by=By.NAME, value= \"submitaction\") #OVERWRITES THE PREVIOUS DOWNLOAD BUTTON\n",
    "    downloadbutton.click()\n",
    "\n",
    "    folder_path = r'C:\\Users\\justi\\Downloads'\n",
    "    file_type = r'\\*CSV'\n",
    "    files = glob.glob(folder_path + file_type)\n",
    "    max_file = max(files, key=os.path.getctime)\n",
    "\n",
    "    try:\n",
    "        downloadeddata = pd.read_csv(max_file, encoding='utf-8')\n",
    "    except:\n",
    "        try:\n",
    "            print('Empty Data Error Occured on file ' + max_file)\n",
    "            downloadeddatafile = open(max_file, 'r')\n",
    "            downloadeddata = pd.read_csv(downloadeddatafile, encoding='utf-8')\n",
    "            downloadeddatafile.close()\n",
    "            continue\n",
    "        except:\n",
    "            print(\"Skipping to next interation\")\n",
    "            continue\n",
    "        \n",
    "    \n",
    "    if masterdataframe.empty:\n",
    "        masterdataframe = pd.DataFrame(data=downloadeddata)\n",
    "    else:\n",
    "        masterdataframe = masterdataframe.append(pd.DataFrame(data = downloadeddata))\n",
    "    driver.switch_to.window(windowbefore)\n",
    "    os.remove(max_file)\n",
    "print('During the search, there were ' + str(emptyresults)+ ' searches with no results.')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''This creates a file of the entire scraped results. No information is omitted. EDIT WITH THE PATH WHERE THIS CSV FILE SHOULD BE STORED\n",
    "ON THE COMPUTER WHERE THIS SCRIPT IS RAN.'''\n",
    "file= masterdataframe.to_csv(r'C:\\Users\\justi\\Downloads\\UMinnAtlasScrapeResults' + str(date.today()) +  '.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''This extracts information from the entire scraped results and inserts them into the bulk upload template. EDIT WITH THE PATH OF WHERE\n",
    "THE BULK UPLOAD TEMPLATE IS ON THE COMPUTER WHERE THIS SCRIPT IS RAN.'''\n",
    "clienttemplate = pd.read_excel(r\"C:\\Users\\justi\\Downloads\\GLANSISSpecimenBulkUploadTemplateTEST.xlsx\").drop('Unnamed: 0', axis=1)\n",
    "clienttemplate[['Genus*', 'Species*', 'Latitude*', 'Longitude*', 'Year*', 'Month', 'Day', 'Collectors', 'Reference ID*', 'Reference 3', 'Number collected/observed', 'Locality*'  ]] = masterdataframe[['genus', 'specificEpithet', 'decimalLatitude', 'decimalLongitude', 'year', 'month', 'day', 'recordedBy', 'id', 'references', 'individualCount', 'locality']]\n",
    "clienttemplate['Source*'] = np.where(clienttemplate['Latitude*'].isna()|clienttemplate['Longitude*'].isna(), '', 'reported')\n",
    "clienttemplate['Accuracy*'] = np.where(clienttemplate['Source*'] == 'reported', 'accurate', '') #\n",
    "clienttemplate['Reference 2']= atlas_url \n",
    "clienttemplate['Record Type*'] = np.where(masterdataframe['collectionCode'].isna(), '', 'specimen')\n",
    "clienttemplate['Year Accuracy of specimen*'] = masterdataframe['year']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''This will save the bulk upload template with the scraped data in it to a csv file. UPLOAD WITH \n",
    "THE PATH OF WHERE THIS FILE SHOULD BE SAVED'''\n",
    "finalBulkUploadSheet = clienttemplate.to_csv(r'C:\\Users\\justi\\Downloads\\UMinnAtlasBulkUploadSheet' + str(date.today())+ '.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "eedb55a3f3d5a08c90a45b02edd9d5201f64a9996f64fdac14a22b56503f46e8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
